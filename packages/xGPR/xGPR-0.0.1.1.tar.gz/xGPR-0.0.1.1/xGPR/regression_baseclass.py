"""Describes the GPRegressionBaseclass from which other model classes inherit.

The GPRegressionBaseclass describes class attributes and methods shared by
model classes like xGPRegression.
"""
import os
import sys
import abc
from abc import ABC

try:
    import cupy as cp
except:
    pass
import numpy as np

from .data_handling.dataset_builder import build_offline_fixed_vector_dataset
from .kernels import KERNEL_NAME_TO_CLASS
from .constants import constants
from .optimizers.lbfgs_optimizer import lbfgs_optimizer
from .optimizers.stochastic_optimizer import stochastic_tuning
from .optimizers.bayes_grid_optimizer import bayes_grid_tuning
from .optimizers.pure_bayes_optimizer import pure_bayes_tuning
from .optimizers.nm_optimizer import nelder_mead_optimizer

class GPRegressionBaseclass(ABC):
    """The base class for xGPR regression classes. Provides shared
    methods and attributes.

    Attributes:
        kernel_choice (str): The kernel selected by the user.
        kernel: The kernel object for the posterior predictive mean. The class of
            this object will depend on the kernel specified by the user -- e.g.
            the 'rbf' kernel corresponds to class Rbf.
        weights: A 1d array, either a cp.ndarray or np.ndarray depending on the
            device specified by the user (cpu or gpu). The random features
            generated by self.kernel are multiplied against the weights to
            generate the posterior predictive mean. The weights are calculated
            during fitting.
        var: A 2d square array, either a cp.ndarray or np.ndarray depending on
            the device specified by the user (cpu or gpu). The random features
            are used in conjunction with var to generate the posterior predictive
            variance. The var is calculated during fitting.
        device (str): One of "gpu", "cpu". The user can update this as desired.
            All predict / tune / fit operations are carried out using the
            current device.
        training_rffs (int): The number of random Fourier features used for
            tuning the hyperparameters.
        fitting_rffs (int): The number of random Fourier features used for
            fitting the model and generating the posterior predictive mean.
        variance_rffs (int): The number of random Fourier features used for
            calculating posterior predictive variance.
        kernel_specific_params (dict): Contains kernel-specific parameters --
            e.g. 'matern_nu' for the nu for the Matern kernel, or 'conv_width'
            for the conv1d kernel.
        verbose (bool): If True, regular updates are printed during
            hyperparameter tuning and fitting.
        double_precision_fht (bool): If False, use single precision floats to generate
            random features. This can increase speed but may result in a slight (usually
            negligible) loss of accuracy.
        trainy_mean (float): The mean of the training ydata. Determined during fitting.
            Used for making predictions.
        trainy_std (float): The standard deviation of the training ydata. Determined
            during fitting. Used for making predictions.
    """

    def __init__(self, training_rffs,
                    fitting_rffs,
                    variance_rffs = 16,
                    kernel_choice="RBF",
                    device = "cpu",
                    kernel_specific_params = constants.DEFAULT_KERNEL_SPEC_PARMS,
                    verbose = True,
                    double_precision_fht = False):
        """Constructor.

        Args:
            training_rffs (int): The number of random Fourier features
                to use for hyperparameter tuning.
            fitting_rffs (int): The number of random Fourier features
                to use for posterior predictive mean (i.e. the predicted
                value for new datapoints).
            variance_rffs (int): The number of random Fourier features
                to use for posterior predictive variance (i.e. calculating
                uncertainty on predictions). Defaults to 64.
            kernel_choice (str): The kernel that the model will use.
                Defaults to 'RBF'. Must be in kernels.kernel_list.
                KERNEL_NAME_TO_CLASS.
            device (str): Determines whether calculations are performed on
                'cpu' or 'gpu'. The initial entry can be changed later
                (i.e. model can be transferred to a different device).
                Defaults to 'cpu'.
            kernel_specific_params (dict): Contains kernel-specific parameters --
                e.g. 'matern_nu' for the nu for the Matern kernel, or 'conv_width'
                for the conv1d kernel.
            verbose (bool): If True, regular updates are printed
                during fitting and tuning. Defaults to True.
            double_precision_fht (bool): If False, use single precision floats to generate
                random features. This can increase speed but may result in a slight (usually
                negligible) loss of accuracy.
        """
        self.kernel_choice = kernel_choice
        self.kernel = None
        self.weights = None
        self.var = None
        self.device = device

        self.training_rffs = training_rffs
        self.fitting_rffs = fitting_rffs
        #Variance_rffs must be <= fitting_rffs. Always set second
        self.variance_rffs = variance_rffs

        self.kernel_spec_parms = kernel_specific_params
        self.double_precision_fht = double_precision_fht

        self.verbose = verbose
        self.trainy_mean = 0.0
        self.trainy_std = 1.0


    #First, abstract methods required for subclasses.

    @abc.abstractmethod
    def exact_nmll_gradient(self):
        """Subclasses must implement a method that calculates
        the gradient of the negative marginal log likelihood."""

    @abc.abstractmethod
    def exact_nmll(self, hyperparams, tuning_dataset, verbose = False,
            suppress_warnings = False):
        """Subclasses must implement a method that calculates
        the negative marginal log likelihood."""

    @abc.abstractmethod
    def gridsearch_nmll(self, sigma_vals, dataset, bounds,
            n_pts_per_dim = 40, min_eigval = 1e-6):
        """Child must implement a method that can
        perform grid search for shared hyperparameters."""

    @abc.abstractmethod
    def _calc_weights_exact(self, dataset):
        """Child must implement a method that can
        calculate the weights using matrix decomposition when
        self.fitting_rffs is sufficiently small."""

    @abc.abstractmethod
    def _calc_weights_cg(self, dataset, cg_tol = 1e-5,
                        max_iter = 500, preconditioner = None):
        """Child must implement a method that can
        calculate the weights using conjugate gradients."""

    @abc.abstractmethod
    def _calc_weights_lbfgs(self, fitting_dataset, tol, max_iter = 500):
        """Child must implement a method that can calculate the weights
        using L-BFGS."""



    @abc.abstractmethod
    def _calc_weights_sgd(self, fitting_dataset, tol, max_iter = 100,
            preconditioner = None, manual_lr = None):
        """Child must implement a method that can calculate the weights
        using SGD."""

    @abc.abstractmethod
    def _calc_weights_ams(self, fitting_dataset, tol, max_iter = 50):
        """Child must implement a method that can calculate the weights
        using amsgrad."""


    @abc.abstractmethod
    def _calc_variance(self, dataset):
        """Subclasses must implement a method that can
        calculate the variance matrix (self.var)."""



    def _initialize_kernel(self, kernel_choice, input_dims, num_rffs,
                        random_seed, bounds = None):
        """Selects and initializes an appropriate kernel object based on the
        kernel_choice string supplied by caller. The kernel is then moved to
        the appropriate device based on the 'device' supplied by caller
        and is returned.

        Args:
            kernel_choice (str): The kernel selection. Must be one of
                constants.ACCEPTABLE_KERNELS.
            input_dims (list): The dimensions of the data. A list of
                [ndatapoints, x.shape[1]] for non-convolution data
                or [ndatapoints, x.shape[1], x.shape[2]] for conv1d
                data.
            num_rffs (int): The number of random features the kernel
                object should generate.
            random_seed (int): The random seed to the random number
                generator the kernel uses to initialize.
            bounds (np.ndarray): The bounds on hyperparameter
                tuning. Must have an appropriate shape for the
                selected kernel. If None, the kernel will use
                its defaults. Defaults to None.

        Returns:
            kernel: An object of the appropriate kernel class.

        Raises:
            ValueError: Raises a value error if an unrecognized kernel
                is supplied.
        """
        if kernel_choice not in KERNEL_NAME_TO_CLASS:
            raise ValueError("An unrecognized kernel choice was supplied.")
        kernel = KERNEL_NAME_TO_CLASS[kernel_choice](input_dims,
                            num_rffs, random_seed, self.device,
                            self.double_precision_fht,
                            kernel_spec_parms = self.kernel_spec_parms)
        if bounds is not None:
            kernel.set_bounds(bounds)
        return kernel


    def _pretransform_dataset(self, dataset, pretransform_location):
        """Pretransforms a dataset, generating the random features without
        applying the activation function then saving these pre-generated
        features (to which only the final processing step needs to be applied)
        to disk. If the number of features is small but the number of datapoints
        is large, or if an SSD hard drive is available, this can bring about
        a substantial speedup.

        Args:
            dataset: An object of class CPUOnlineDataset, CPUOfflineDataset,
                GPUOnlineDataset or GPUOfflineDataset. Contains the prechecked
                data as either a list of on-disk arrays or a set of numpy arrays.
            pretransform_location (str): A valid filepath to a directory where
                the pretransformed arrays can be saved.
        """
        if self.verbose:
            print("Now pretransforming data.")
        if self.kernel is None:
            raise ValueError("Tried to pretransform data without an initialized kernel.")
        current_dir = os.getcwd()
        os.chdir(pretransform_location)
        xfiles, yfiles = [], []
        max_chunk_size = 0

        for i, (xbatch, ybatch) in enumerate(dataset.get_chunked_data()):
            xfile, yfile = f"PRETRANSFORMED_{i}_X.npy", f"PRETRANSFORMED_{i}_Y.npy"
            xbatch = self.kernel.transform_x(xbatch)
            if self.device == "gpu":
                xbatch = cp.asnumpy(xbatch).astype(np.float32)
                ybatch = cp.asnumpy(ybatch)
            else:
                xbatch = xbatch.astype(np.float32)
            ybatch = ybatch * dataset.get_ystd() + dataset.get_ymean()
            np.save(xfile, xbatch)
            np.save(yfile, ybatch)
            xfiles.append(xfile)
            yfiles.append(yfile)
            max_chunk_size = max(max_chunk_size, xbatch.shape[0])

        tuning_dataset = build_offline_fixed_vector_dataset(xfiles,
                            yfiles, chunk_size = max_chunk_size,
                            skip_safety_checks = True)
        tuning_dataset.pretransformed = True
        tuning_dataset.parent_xdim = dataset.get_xdim()

        os.chdir(current_dir)
        return tuning_dataset

    #############################
    #The next block of functions are used for tuning hyperparameters. We provide
    #a variety of strategies (the user can additionally combine them
    #to generate more), with some strong recommendations on which to use when
    #(see docs).
    #############################


    def tune_hyperparams_minimal_bayes(self, dataset, random_seed = 123,
                    max_bayes_iter = 30, run_diagnostics = False,
                    bounds = None, tol = 1e-2, min_eigval = 1e-5,
                    n_init_pts = 0, grid_pts_per_lb = 40):
        """Tunes the hyperparameters using Bayesian optimization, but reduces
        the dimensionality by 2 by optimizing over lambda and beta (hyperparameters
        shared by all kernels) using an efficient strategy.
        This works very well for 3 hyperparameter kernels, reasonably
        well for four hyperparameter kernels. Because it uses an eigendecomposition,
        it has poor scaling with # random features and is thus only applicable if the
        number of random features is <= 8000-10000 on GPU (on CPU, significantly less
        is recommended).

        Args:
            dataset: Object of class OnlineDataset or OfflineDataset.
            random_seed (int): A random seed for the random
                number generator. Defaults to 123.
            max_bayes_iter (int): The maximum number of iterations of Bayesian
                optimization. For kernels with 4 hyperparameters this
                will be overriden in favor of a default value.
            run_diagnostics (bool): If True, the number of iterations and
                the best achieved score are returned.
            bounds (np.ndarray): The bounds for optimization. Defaults to
                None, in which case the kernel uses its default bounds.
                If supplied, must be a 2d numpy array of shape (num_hyperparams, 2).
            tol (float): Criteria for convergence.
            min_eigval (float): The smallest acceptable eigenvalue of Z^T Z + lambda I
                in order for the corresponding hyperparameter combination to be considered
                acceptable. Occasionally due to numerical error for very-close-to-singular
                matrices the marginal likelihood may be incorrectly calculated. The min_eigval
                threshold ensures that hyperparameter combinations which generate such matrices
                are ruled out and not considered as 'valid'. It will be obvious that this
                has occurred if hyperparameter combinations yield very low scores
                (huge negative numbers) during tuning. A lower setting for min_eigval
                risks numerical error but may enable you to find (slightly) better solutions.
                You should not normally need to change this value. If reducing min_eigval,
                make sure that you use reasonable bounds for the hyperparameter search to
                avoid likelihood of numerical error.
            n_init_pts (int): The number of initial points evaluated. If 0, the optimizer
                uses reasonable defaults.
            grid_pts_per_lb (int): The number of grid points per each of the shared
                hyperparameters. The default is usually quite sufficient.

            Returns:
                Does not return anything unless run_diagnostics is True.
                hyperparams (np.ndarray): The best hyperparams found during optimization.
                n_feval (int): The number of function evaluations during optimization.
                best_score (float): The best negative marginal log-likelihood achieved.
                gridscores (tuple): A tuple of 2 numpy arrays. The first contains
                    the sigma values (kernel specific hyperparameters) for each
                    point evaluated. The second contains the scores for each point.
                    Occasionally useful for evaluating how kernel hyperparameters affect
                    marginal likelihood for a given number of RFFs.

            Raises:
                ValueError: The input dataset is checked for validity before tuning is
                    initiated. If problems are found, a ValueError will provide an
                    explanation of the error. This method will also raise a ValueError
                    if you try to use it on a kernel with > 4 hyperparameters (since
                    Bayesian tuning loses efficiency in high dimensions rapidly).
            """
        bounds = self._run_pretuning_prep(dataset, random_seed, bounds)
        hyperparams, gridscores, best_score, n_feval = bayes_grid_tuning(
                                        self.gridsearch_nmll,
                                        dataset, bounds, random_seed,
                                        max_iter = max_bayes_iter,
                                        verbose = self.verbose, tol = tol,
                                        min_eigval = min_eigval,
                                        init_pts = n_init_pts,
                                        grid_pts_per_lb = grid_pts_per_lb)
        self._post_tuning_cleanup(dataset, hyperparams)
        if run_diagnostics:
            return hyperparams, n_feval, best_score, gridscores



    def tune_hyperparams_pure_bayes(self, dataset, bounds, random_seed = 123,
                    max_bayes_iter = 30, run_diagnostics = False,
                    starting_hyperparams = None, tol = 1e-2):
        """Tunes the hyperparameters using Bayesian optimization, WITHOUT
        reducing the dimensionality (in contrast to minimal_bayes). This means
        that no eigendecomposition is required, which makes each iteration cheaper and
        allows for using a larger number of training_rffs, BUT means that the dimensionality
        of the space searched is increased by 2 relative to minimal_bayes.
        As a result, this algorithm is not very efficient for searching the entire
        hyperparameter space, BUT for 3 and 4 hyperparameter kernels, it can be effective
        for searching some bounded region. This algorithm uses a Cholesky decomposition
        and thus does not scale well past 10,000 random features.

        Args:
            dataset: Object of class OnlineDataset or OfflineDataset.
            random_seed (int): A random seed for the random
                number generator. Defaults to 123.
            max_bayes_iter (int): The maximum number of iterations of Bayesian
                optimization.
            run_diagnostics (bool): If True, the number of iterations and
                the best achieved score are returned.
            bounds (np.ndarray): The bounds for optimization. Must be supplied,
                in contrast to most other tuning routines, since this routine
                is more seldom used for searching the whole hyperparameter space.
                Must be a 2d numpy array of shape (num_hyperparams, 2).
            starting_hyperparams (np.ndarray): Either None or a 1d numpy array of shape
                (num_hyperparams). The score will be assessed at this point in the
                first phase of optimization.
            tol (float): Criteria for convergence.

            Returns:
                Does not return anything unless run_diagnostics is True.
                hyperparams (np.ndarray): The best hyperparams found during optimization.
                n_feval (int): The number of function evaluations during optimization.
                best_score (float): The best negative marginal log-likelihood achieved.

            Raises:
                ValueError: The input dataset is checked for validity before tuning is
                    initiated. If problems are found, a ValueError will provide an
                    explanation of the error. This method will also raise a ValueError
                    if you try to use it on a kernel with > 4 hyperparameters (since
                    Bayesian tuning loses efficiency in high dimensions rapidly).
            """
        init_hyperparams = starting_hyperparams
        if init_hyperparams is None and self.kernel is not None:
            init_hyperparams = self.kernel.get_hyperparams(logspace=True)
        bounds = self._run_pretuning_prep(dataset, random_seed, bounds)
        hyperparams, best_score, n_feval = pure_bayes_tuning(
                                        self.exact_nmll,
                                        dataset, bounds, random_seed,
                                        max_iter = max_bayes_iter,
                                        starting_hyperparams = init_hyperparams,
                                        verbose = self.verbose, tol = tol)
        self._post_tuning_cleanup(dataset, hyperparams)
        if run_diagnostics:
            return hyperparams, n_feval, best_score


    def tune_hyperparams_nelder(self, dataset, bounds, starting_hyperparams = None,
                    random_seed = 123, max_iter = 50, run_diagnostics = False, tol = 1e-2):
        """Tunes hyperparameters using Nelder-Mead, a sometimes useful heuristic.
        This is generally not useful for searching the whole hyperparameter space -- it
        is not efficient, because multiple restarts may be required. If given a good starting
        point, however, it can work pretty well, although it is slow.

        Args:
            dataset: Object of class OnlineDataset or OfflineDataset.
            bounds (np.ndarray): The bounds for optimization. Must be supplied,
                in contrast to most other tuning routines, since this routine
                is more seldom used for searching the whole hyperparameter space.
                Must be a 2d numpy array of shape (num_hyperparams, 2).
            starting_hyperparams (np.ndarray): A starting point for optimization.
                Defaults to None. If None, randomly selected locations are used.
            random_seed (int): Seed for the random number generator.
            max_iter (int): The maximum number of iterations.
            run_diagnostics (bool): If True, the number of iterations and
                the best achieved score are returned.
            tol (float): Criteria for convergence.

            Returns:
                Does not return anything unless run_diagnostics is True.
                hyperparams (np.ndarray): The best hyperparams found during optimization.
                n_feval (int): The number of function evaluations during optimization.
                best_score (float): The best negative marginal log-likelihood achieved.

            Raises:
                ValueError: The input dataset is checked for validity before tuning is
                    initiated. If problems are found, a ValueError will provide an
                    explanation of the error.
            """
        bounds = self._run_pretuning_prep(dataset, random_seed, bounds)
        if starting_hyperparams is None:
            init_hyperparams = np.mean(bounds, axis=1)
        else:
            init_hyperparams = starting_hyperparams
        hyperparams, best_score, n_feval = nelder_mead_optimizer(dataset,
                                        self.exact_nmll, bounds,
                                        max_iter, init_hyperparams,
                                        self.verbose, tol)
        self._post_tuning_cleanup(dataset, hyperparams)
        if run_diagnostics:
            return hyperparams, n_feval, best_score


    def tune_hyperparams_lbfgs(self, dataset, random_seed = 123,
            max_iter = 50, n_restarts = 1, starting_hyperparams = None,
            run_diagnostics = False, bounds = None):
        """Tunes the hyperparameters using the L-BFGS algorithm.
        It uses either a supplied set of starting hyperparameters OR
        randomly chosen locations. If the latter, it is run
        n_restarts times.

        Args:
            dataset: Object of class OnlineDataset or OfflineDataset.
            random_seed (int): A random seed for the random
                number generator. Defaults to 123.
            max_iter (int): The maximum number of iterations for
                which l-bfgs should be run per restart. Defaults to 50.
            n_restarts (int): The maximum number of restarts to run
                l-bfgs. Ignored if starting_hyperparams are supplied.
            starting_hyperparams (np.ndarray): A starting point for l-bfgs
                based optimization. Defaults to None. If None, randomly
                selected locations are used.
            run_diagnostics (bool): If True, the number of iterations and
                the best achieved score are returned.
            bounds (np.ndarray): The bounds for optimization. Defaults to
                None, in which case the kernel uses its default bounds.
                If supplied, must be a 2d numpy array of shape (num_hyperparams, 2).

            Returns:
                Does not return anything unless run_diagnostics is True.
                hyperparams (np.ndarray): The best hyperparams found during optimization.
                n_feval (int): The number of function evaluations during optimization.
                best_score (float): The best negative marginal log-likelihood achieved.

            Raises:
                ValueError: The input dataset is checked for validity before tuning is
                    initiated. If problems are found, a ValueError will provide an
                    explanation of the error.
            """
        init_hyperparams = starting_hyperparams
        if init_hyperparams is None:
            if self.kernel is not None:
                init_hyperparams = self.kernel.get_hyperparams(logspace=True)
        bounds = self._run_pretuning_prep(dataset, random_seed, bounds)
        hyperparams, best_score, n_feval = lbfgs_optimizer(dataset,
                            self.exact_nmll_gradient, bounds,
                            random_seed, n_restarts, max_iter,
                            init_hyperparams, self.verbose)
        self._post_tuning_cleanup(dataset, hyperparams)
        if run_diagnostics:
            return hyperparams, n_feval, best_score

    def tune_hyperparams_grid(self, dataset, random_seed = 123,
            grid_pts_per_dim = 40, bounds = None,
            run_diagnostics = False, min_eigval = 1e-5):
        """Runs a grid search (only applicable to 2 hyperparameter kernels).
        This is an extremely efficient approach for the polynomial and
        linear kernels, and not useful for anything else. Use for polynomial
        and linear in preference to any other method, do not use for anything
        else.

        Args:
            dataset: Object of class OnlineDataset or OfflineDataset.
            random_seed (int): A random seed for the random
                number generator. Defaults to 123.
            grid_pts_per_dim (int): The number of grid points per hyperparameter.
            bounds (np.ndarray): The bounds for optimization. Defaults to
                None, in which case the kernel uses its default bounds.
                If supplied, must be a 2d numpy array of shape (num_hyperparams, 2).
            run_diagnostics (bool): If True, return the best hyperparameters and
                the nmll score.
            min_eigval (float): The smallest acceptable eigenvalue of Z^T Z + lambda I
                in order for the corresponding hyperparameter combination to be considered
                acceptable. Occasionally due to numerical error for very-close-to-singular
                matrices the marginal likelihood may be incorrectly calculated. The min_eigval
                threshold ensures that hyperparameter combinations which generate such matrices
                are ruled out and not considered as 'valid'. It will be obvious that this
                has occurred if hyperparameter combinations which yield very poor accuracy
                on the training or validation set, yield very low scores (large negative numbers)
                during tuning. The default value is normally a good one.

            Raises:
                ValueError: The input dataset is checked for validity before tuning is
                    initiated. If problems are found, a ValueError will provide an
                    explanation of the error.

            Returns:
                Nothing is returned unless run_diagnostics is True.
                hyperparams (np.ndarray): The best hyperparameters identified.
                nmll (float): The best nmll score from tuning.
            """
        bounds = self._run_pretuning_prep(dataset, random_seed, bounds)
        if bounds.shape[0] != 2:
            raise ValueError("The grid optimizer is only applicable for kernels "
                "with 2 hyperparameters.")
        scoregrid, hyperparams = self.gridsearch_nmll(None, dataset, bounds,
                                grid_pts_per_dim, min_eigval)
        self._post_tuning_cleanup(dataset, hyperparams)
        if self.verbose:
            print("Grid acquired.")
        if run_diagnostics:
            return hyperparams, scoregrid.min()


    def tune_hyperparams_sgd(self, dataset, random_seed = 123,
            n_epochs = 1, minibatch_size = 2000, lr = 0.02,
            n_restarts = 3, starting_hyperparams = None,
            run_diagnostics = False, tol = 1e-3, bounds = None):
        """Tunes the hyperparameters using EITHER the Adam algorithm
        OR stochastic variance reduction gradient descent.
        It uses either a supplied set of starting hyperparameters OR
        randomly chosen locations. If the latter, it is run
        n_restarts times.

        Args:
            dataset: Object of class OnlineDataset or OfflineDataset.
            random_seed (int): A random seed for the random
                number generator.
            n_epochs: The maximum number of epochs per restart.
            minibatch_size (int): The size of the minibatches.
            lr (float): The learning rate for the Adam algorithm if Adam is used,
                or the starting learning rate for sgdvr if sgdvr is used.
            n_restarts (int): The maximum number of restarts to run.
                Ignored if starting_hyperparams are supplied.
            starting_hyperparams (np.ndarray): A starting point for
                optimization. If None, randomly selected locations are used.
            run_diagnostics (bool): If True, the number of iterations and
                the best achieved score are returned.
            tol (float): The threshold for convergence.
            bounds (np.ndarray): The bounds for optimization. Defaults to
                None, in which case the kernel uses its default bounds.
                If supplied, must be a 2d numpy array of shape (num_hyperparams, 2).

            Returns:
                Does not return anything unless run_diagnostics is True.
                hyperparams (np.ndarray): The best hyperparams found during optimization.
                n_feval (int): The number of function evaluations during optimization.
                best_score (float): The best negative marginal log-likelihood achieved.

            Raises:
                ValueError: The input dataset is checked for validity before tuning is
                    initiated. If problems are found, a ValueError will provide an
                    explanation of the error.
            """
        init_hyperparams = starting_hyperparams
        if init_hyperparams is None:
            if self.kernel is not None:
                init_hyperparams = self.kernel.get_hyperparams(logspace=True)
        bounds = self._run_pretuning_prep(dataset, random_seed, bounds)
        hyperparams, _, n_feval = stochastic_tuning(dataset,
                            minibatch_size, n_epochs,
                            lr, random_seed, init_hyperparams,
                            n_restarts, bounds, tol,
                            self.exact_nmll_gradient,
                            self.verbose)
        if run_diagnostics:
            best_score = self.exact_nmll(hyperparams, dataset, verbose=False,
                    suppress_warnings=False)
        self._post_tuning_cleanup(dataset, hyperparams)
        if run_diagnostics:
            return hyperparams, n_feval, best_score




    def _run_pretuning_prep(self, input_dataset, random_seed, input_bounds = None):
        """Checks the dataset supplied by the user to ensure
        it is consistent with the kernel choice and other user selections.
        Initializes the kernel and pretransforms the data (if appropriate).

        Args:
            dataset: Object of class OnlineDataset or OfflineDataset.
                You should generate this object using either the
                build_online_dataset, build_offline_fixed_vector_dataset
                or build_offline_sequence_dataset functions under
                data_handling.dataset_builder, or a static_layer if applicable.
            random_seed (int): A random seed for the random number generator.
            input_bounds (np.ndarray): The bounds for optimization. Defaults to
                None, in which case the kernel uses its default bounds.
                If supplied, must be a 2d numpy array of shape (num_hyperparams, 2).

        Returns:
            tuning_dataset: An OnlineDataset or OfflineDataset. If pretransformation
                was specified, this is the pretransformed data. If not, it is
                a reference to the input dataset.
            bounds (np.ndarray): If input_bounds were specified, these are the input_bounds
                specified by the user. If not, they are the kernel's defaults.
        """
        if self.verbose:
            print("starting_tuning")
        if input_dataset.pretransformed:
            raise ValueError("You cannot supply a pretransformed dataset for tuning.")

        input_dataset.device = self.device
        self.kernel = None
        self.weights, self.var = None, None

        if self.device == "gpu":
            mempool = cp.get_default_memory_pool()
            mempool.free_all_blocks()
        self.kernel = self._initialize_kernel(self.kernel_choice, input_dataset.get_xdim(),
                        self.training_rffs, random_seed, input_bounds)

        if input_bounds is None:
            bounds = self.kernel.get_bounds(logspace=True)
        else:
            bounds = input_bounds
        #We check num rffs AFTER initializing the kernel, since one kernel (Linear!)
        #will override requested number of rffs.
        if self.kernel.get_num_rffs() > constants.MAX_TRAINING_RFFS:
            raise ValueError(f"At most {constants.MAX_TRAINING_RFFS} can be used "
                        "for tuning hyperparameters using this method. Try tuning "
                        "using the max and then fine-tuning optimization_toolkit.")

        return bounds


    def _post_tuning_cleanup(self, input_dataset, best_hyperparams):
        """Runs some post-tuning cleanup operations
        that are common to all optimization strategies."""
        if self.verbose:
            print("Tuning complete.")
        input_dataset.device = "cpu"
        self.kernel.set_hyperparams(best_hyperparams, logspace=True)
        if self.device == "gpu":
            mempool = cp.get_default_memory_pool()
            mempool.free_all_blocks()


    #############################
    #The next block of functions are used for fitting models once the hyperparameters
    #have been tuned (or, alternatively, fitting using user-supplied hyperparameters).
    #############################


    def pretransform_data(self, input_dataset, pretransform_dir,
            random_seed = 123, hyperparams = None):
        """Pretransforms the data using the kernel (initializing one if
        none present), in other words, pre-generates random features and
        saves them on disk. This is GREATLY preferable if you are fitting
        on CPU, and even on GPU may be much faster for convolution kernels.
        It may however take up a large amount of diskspace if both the
        dataset and the number of random features are very large.

        Args:
            input_dataset: A Dataset object.
            random_seed (int): A random seed for the random number generator.
            hyperparams (np.ndarray): Either None or a user-supplied numpy array
                containing the hyperparameters. It must be valid for the kernel
                in question. If None, the hyperparameters must already have been
                tuned so that self.kernel is not None. If neither of these is True,
                a ValueError will be raised.
            pretransform_dir (str): A valid filepath to a directory.

        Returns:
            output_datset: A Dataset object with the pretransformed training data.
        """
        self._run_fitting_prep(input_dataset, random_seed, hyperparams)
        fitting_dataset = self._pretransform_dataset(input_dataset, pretransform_dir)
        fitting_dataset.device = self.device
        return fitting_dataset


    def _run_fitting_prep(self, input_dataset, random_seed, hyperparams = None):
        """Checks the dataset supplied by the user to ensure
        it is consistent with the kernel choice and other user selections.

        Args:
            dataset: A Dataset object.
            random_seed (int): A random seed for the random number generator.
            hyperparams (np.ndarray): Either None or a user-supplied numpy array
                containing the hyperparameters. It must be valid for the kernel
                in question. If None, the hyperparameters must already have been
                tuned so that self.kernel is not None. If neither of these is True,
                a ValueError will be raised.
        """
        if self.device == "gpu":
            mempool = cp.get_default_memory_pool()
            mempool.free_all_blocks()

        input_dataset.device = self.device

        self.weights, self.var = None, None
        self.trainy_mean = input_dataset.get_ymean()
        self.trainy_std = input_dataset.get_ystd()

        if hyperparams is None:
            if self.kernel is None:
                raise ValueError("In order to fit, either hyperparameters should first "
                        "have been tuned, or user-specified hyperparameters must be "
                        "supplied.")
            starting_hparams = self.kernel.get_hyperparams(logspace = True)
        else:
            starting_hparams = hyperparams
        #It's better to reinitialize the kernel. This may seem wasteful BUT it's
        #actually very cheap for FHT kernels AND if the user has changed anything
        #(kernel_spec_parms,
        #fitting_rffs etc.) since the time that they initialized the model,
        #we'll need to reinitialize the kernel anyway. As long as we've kept
        #the hyperparameters -- that's the important piece. Also, as long
        #as user is using the same random seed, kernel will be the same anyway.
        if input_dataset.pretransformed:
            xdim = input_dataset.parent_xdim
        else:
            xdim = input_dataset.get_xdim()
        self.kernel = self._initialize_kernel(self.kernel_choice,
                        xdim, self.fitting_rffs, random_seed)

        self.kernel.check_hyperparams(starting_hparams)
        self.kernel.set_hyperparams(starting_hparams, logspace = True)



    def fit(self, dataset, preconditioner = None,
                tol = 1e-6, preset_hyperparams=None, max_iter = 500,
                random_seed = 123, run_diagnostics = False,
                mode = "cg", suppress_var = False,
                manual_lr = None):
        """Fits the model after checking that the input data
        is consistent with the kernel choice and other user selections.

        Args:
            dataset: Object of class OnlineDataset or OfflineDataset.
            preconditioner: Either None or a valid Preconditioner (e.g.
                CudaRandomizedPreconditioner, CPURandomizedPreconditioner
                etc). If None, no preconditioning is used.
            tol (float): The threshold below which iterative strategies (L-BFGS, CG,
                SGD) are deemed to have converged. Defaults to 1e-5. Note that how
                reaching the threshold is assessed may depend on the algorithm.
            preset_hyperparams: Either None or a numpy array. If None,
                hyperparameters must already have been tuned using one
                of the tuning methods (e.g. tune_hyperparams_bayes_bfgs).
                If supplied, must be a numpy array of shape (N, 2) where
                N is the number of hyperparams for the kernel in question.
            max_iter (int): The maximum number of epochs for iterative strategies.
            random_seed (int): The random seed for the random number generator.
            run_diagnostics (bool): If True, the number of conjugate
                gradients and the preconditioner diagnostics ratio are returned.
            mode (str): Must be one of "sgd", "amsgrad", "cg", "lbfgs", "exact".
                Determines the approach used. If 'exact', self.kernel.get_num_rffs
                must be <= constants.constants.MAX_CLOSED_FORM_RFFS.
            suppress_var (bool): If True, do not calculate variance. This is generally only
                useful when optimizing hyperparameters, since otherwise we want to calculate
                the variance. It is best to leave this as default False unless performing
                hyperparameter optimization.
            manual_lr (float): Either None or a float. If not None, this is the initial
                learning rate used for stochastic gradient descent or ams grad (ignored
                for all other fitting modes). If None, the algorithm will try to determine
                a good initial learning rate itself.

        Returns:
            Does not return anything unless run_diagnostics is True.
            n_iter (int): The number of iterations for conjugate gradients, L-BFGS or sgd.
            losses (list): The loss on each iteration. Only for SGD and CG, otherwise,
                empty list.

        Raises:
            ValueError: The input dataset is checked for validity before tuning is
                initiated, an error is raised if problems are found.
        """
        self._run_fitting_prep(dataset, random_seed, preset_hyperparams)
        if self.verbose:
            print("starting fitting")
        n_iter, losses = 0, []
        if mode == "exact":
            if self.kernel.get_num_rffs() > constants.MAX_CLOSED_FORM_RFFS:
                raise ValueError("You specified 'exact' fitting, but self.fitting_rffs is "
                        f"> {constants.MAX_CLOSED_FORM_RFFS}.")
            self.weights = self._calc_weights_exact(dataset)
        elif mode == "cg":
            self.weights, n_iter, losses = self._calc_weights_cg(dataset,
                                        cg_tol = tol, preconditioner = preconditioner,
                                        max_iter = max_iter)
        elif mode == "lbfgs":
            self.weights, n_iter = self._calc_weights_lbfgs(dataset,
                                        tol = tol, max_iter = max_iter)
        elif mode == "sgd":
            self.weights, n_iter, losses = self._calc_weights_sgd(dataset,
                                        tol = tol, max_iter = max_iter,
                                        preconditioner = preconditioner,
                                        manual_lr = manual_lr)

        elif mode == "amsgrad":
            self.weights, n_iter, losses = self._calc_weights_ams(dataset,
                                        tol = tol, max_iter = max_iter)
        else:
            raise ValueError("Unrecognized fitting mode supplied. Must provide one of "
                        "'lbfgs', 'cg', 'sgd', 'amsgrad', 'exact'.")
        if not suppress_var:
            self.var = self._calc_variance(dataset)

        if self.verbose:
            print("Fitting complete.")
        if self.device == "gpu":
            mempool = cp.get_default_memory_pool()
            mempool.free_all_blocks()
        if run_diagnostics:
            return n_iter, losses


    @property
    def kernel_spec_parms(self):
        """Property definition for the kernel_spec_parms."""
        return self._kernel_spec_parms

    @kernel_spec_parms.setter
    def kernel_spec_parms(self, value):
        """Setter for kernel_spec_parms."""
        if not isinstance(value, dict):
            raise ValueError("Tried to set kernel_spec_parms to something that "
                    "was not a dict!")
        self._kernel_spec_parms = value


    @property
    def kernel_choice(self):
        """Property definition for the kernel_choice attribute."""
        return self._kernel_choice

    @kernel_choice.setter
    def kernel_choice(self, value):
        """Setter for the kernel_choice attribute."""
        if not isinstance(value, str):
            raise ValueError("You supplied a kernel_choice that is not a string.")
        if value not in KERNEL_NAME_TO_CLASS:
            raise ValueError("You supplied an unrecognized kernel.")
        self._kernel_choice = value

    @property
    def fitting_rffs(self):
        """Property definition for the fitting_rffs attribute."""
        return self._fitting_rffs

    @fitting_rffs.setter
    def fitting_rffs(self, value):
        """Setter for the fitting_rffs attribute."""
        self._fitting_rffs = value


    @property
    def training_rffs(self):
        """Property definition for the training_rffs attribute."""
        return self._training_rffs

    @training_rffs.setter
    def training_rffs(self, value):
        """Setter for the training_rffs attribute."""
        self._training_rffs = value

    @property
    def variance_rffs(self):
        """Property definition for the variance_rffs attribute."""
        return self._variance_rffs

    @variance_rffs.setter
    def variance_rffs(self, value):
        """Setter for the variance_rffs attribute."""
        if value > constants.MAX_VARIANCE_RFFS:
            raise ValueError("Currently to keep computational expense at acceptable "
                    f"levels variance rffs is capped at {constants.MAX_VARIANCE_RFFS}.")
        if value > self.fitting_rffs:
            raise ValueError("variance_rffs must be <= fitting_rffs.")
        self._variance_rffs = value


    @property
    def double_precision_fht(self):
        """Property definition for the double_precision_fht attribute."""
        return self._double_precision_fht

    @double_precision_fht.setter
    def double_precision_fht(self, value):
        """Setter for the double_precision_fht attribute."""
        self._double_precision_fht = value

    @property
    def device(self):
        """Property definition for the device attribute."""
        return self._device

    @device.setter
    def device(self, value):
        """Setter for the device attribute."""
        if value not in ["cpu", "gpu"]:
            raise ValueError("Device must be in ['cpu', 'gpu'].")

        if "cupy" not in sys.modules and value == "gpu":
            raise ValueError("You have specified the gpu fit mode but CuPy is "
                "not installed. Currently CPU only fitting is available.")

        if "cuda_basic_hadamard_operations" not in sys.modules and value == "gpu":
            raise ValueError("You have specified the gpu fit mode but the "
                "cudaHadamardTransform module is not installed / "
                "does not appear to have installed correctly. "
                "Currently CPU only fitting is available.")

        if self.kernel is not None:
            self.kernel.device = value
        if self.weights is not None:
            if value == "gpu":
                self.weights = cp.asarray(self.weights)
            elif value == "cpu" and not isinstance(self.weights, np.ndarray):
                self.weights = cp.asnumpy(self.weights)
        if self.var is not None:
            if value == "gpu":
                self.var = cp.asarray(self.var)
            elif value == "cpu" and not isinstance(self.weights, np.ndarray):
                self.weights = cp.asnumpy(self.var)
        if value == "gpu":
            mempool = cp.get_default_memory_pool()
            mempool.free_all_blocks()
        self._device = value
